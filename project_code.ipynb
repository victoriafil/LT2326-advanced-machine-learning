{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a8e3645-759a-465f-b288-c72734be4b3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-01 21:44:11.124769: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchtext.data import Field, TabularDataset, BucketIterator\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler\n",
    "from torch.optim import AdamW\n",
    "\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer, GPT2Config, get_linear_schedule_with_warmup\n",
    "\n",
    "import os, csv\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import preprocessing \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "#model hyperparameters\n",
    "device = torch.device('cuda:2')\n",
    "learning_rate = 1e-4\n",
    "eps = 1e-8\n",
    "warmup_steps = 50\n",
    "\n",
    "max_len = 512\n",
    "\n",
    "batch_size = 5\n",
    "epochs = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d80599a5-2152-4bba-b916-8e694a2e8861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6322\n"
     ]
    }
   ],
   "source": [
    "path1 = \"archive/topics\"\n",
    "path2 = \"archive/forms\"\n",
    "\n",
    "def remove_ending(text):\n",
    "    lines = text.split('\\n')\n",
    "    filtered_lines = [line for line in lines if not line.strip().startswith((\"Copyright\", \"©\", \"copyright\"))]\n",
    "    cleaned_text = '\\n'.join(filtered_lines)\n",
    "    return cleaned_text\n",
    "\n",
    "def find_topics_forms(path, name):\n",
    "    list_of_dict_of_poems = []\n",
    "    for root, _, files in os.walk(path):\n",
    "        for text in files:\n",
    "            fullpath = root + \"/\" + text\n",
    "            topic_or_form = os.path.basename(root)\n",
    "            with open(fullpath, \"r\") as myfile:\n",
    "                poem = myfile.read()\n",
    "                poem = remove_ending(poem)\n",
    "                #poem = poem.replace(\"\\n\", \" <newline> \")\n",
    "                title = text\n",
    "                dictionary = {\"title\" : title , \"poem\" : poem, name : topic_or_form}\n",
    "                list_of_dict_of_poems.append(dictionary)\n",
    "    \n",
    "    return list_of_dict_of_poems\n",
    "\n",
    "poem_topic_dictionary = find_topics_forms(path1, \"topic\")\n",
    "poem_form_dictionary = find_topics_forms(path2, \"form\")\n",
    "print(len(poem_form_dictionary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8f6f552-d0f4-412e-807f-0ff7471eb82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_table(dictionary, name):\n",
    "    column_names=[\"title\",\"poem\", name]\n",
    "    \n",
    "    df = pd.DataFrame(dictionary, columns=column_names)\n",
    "    filepath = name + \"s_dataset.csv\"\n",
    "    file = df.to_csv(filepath, index=False)\n",
    "    read_file = pd.read_csv(filepath)\n",
    "\n",
    "def compare_tables(forms, topics):\n",
    "    forms_f = pd.read_csv(forms)\n",
    "    topics_f = pd.read_csv(topics)\n",
    "    poems_in_forms = forms_f['poem'].tolist()\n",
    "    poems_in_topics = topics_f['poem'].tolist()\n",
    "    for poem in poems_in_forms:\n",
    "        if poem in topics_f['poem'].values:\n",
    "            topic_value = topics_f[topics_f['poem'] == poem]['topic'].values[0]\n",
    "            forms_f.loc[forms_f['poem'] == poem, 'topic'] = topic_value\n",
    "    poems_to_add = [poem for poem in poems_in_topics if poem not in poems_in_forms]\n",
    "    rows_to_add = topics_f[topics_f['poem'].isin(poems_to_add)]\n",
    "    merged_df = pd.concat([forms_f, rows_to_add], ignore_index=True)\n",
    "    merged_df.to_csv('merged_dataset.csv', index=False)\n",
    "\n",
    "create_data_table(poem_form_dictionary, \"form\")\n",
    "create_data_table(poem_topic_dictionary, \"topic\")\n",
    "compare_tables('forms_dataset.csv', 'topics_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90474f6c-38db-4826-a42d-e71d07b6c7ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>poem</th>\n",
       "      <th>form</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AbcPoems2AbcHkAndChinaV2Cauchy3Poembycheungshu...</td>\n",
       "      <td>2 ABC of H.k. and China revised vision.\\nBarre...</td>\n",
       "      <td>abc</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AbcPoems887LiveWithLoveAnAbcPoemPoembyMelvinaG...</td>\n",
       "      <td>Apparently life without love, is no life at al...</td>\n",
       "      <td>abc</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AbcPoemsAAbcAnglesOnAngelsPoemByCauchy3Poembyc...</td>\n",
       "      <td>A abc angles on angels flaws (poem)\\nMix with ...</td>\n",
       "      <td>abc</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AbcPoemsAAbcBrazilDancePoemByCauchy3Poembycheu...</td>\n",
       "      <td>A abc Brazil dance (poem)\\nJack of crack in po...</td>\n",
       "      <td>abc</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AbcPoemsAbc123PoembyGabriellaFranco.txt</td>\n",
       "      <td>ABC... I can't go on\\n123... what's the next o...</td>\n",
       "      <td>abc</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8133</th>\n",
       "      <td>ChildrenPoemsMyImaginaryFriendChildrenPoembyCJ...</td>\n",
       "      <td>My friend, Sherla, was hard to see\\nfor Mom an...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>children</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8134</th>\n",
       "      <td>ChildrenPoemsMyShadowChildrenPoembyCJHeck.txt</td>\n",
       "      <td>I have a shadow hooked to me.\\nSometimes he's ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>children</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8135</th>\n",
       "      <td>ChildrenPoemsMyToothChildrenPoembyCJHeck.txt</td>\n",
       "      <td>The toothfairy took my tooth lath night\\nand l...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>children</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8136</th>\n",
       "      <td>ChildrenPoemsNightNightChildrenPoembyCJHeck.txt</td>\n",
       "      <td>Night-night moon\\nNight-night stars\\nNight-nig...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>children</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8137</th>\n",
       "      <td>RomancePoemsTranceOfRomancePoembynimaldunuhing...</td>\n",
       "      <td>A sapling in a severe drought\\nwhat she needs ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>romance</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8138 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  title  \\\n",
       "0     AbcPoems2AbcHkAndChinaV2Cauchy3Poembycheungshu...   \n",
       "1     AbcPoems887LiveWithLoveAnAbcPoemPoembyMelvinaG...   \n",
       "2     AbcPoemsAAbcAnglesOnAngelsPoemByCauchy3Poembyc...   \n",
       "3     AbcPoemsAAbcBrazilDancePoemByCauchy3Poembycheu...   \n",
       "4               AbcPoemsAbc123PoembyGabriellaFranco.txt   \n",
       "...                                                 ...   \n",
       "8133  ChildrenPoemsMyImaginaryFriendChildrenPoembyCJ...   \n",
       "8134      ChildrenPoemsMyShadowChildrenPoembyCJHeck.txt   \n",
       "8135       ChildrenPoemsMyToothChildrenPoembyCJHeck.txt   \n",
       "8136    ChildrenPoemsNightNightChildrenPoembyCJHeck.txt   \n",
       "8137  RomancePoemsTranceOfRomancePoembynimaldunuhing...   \n",
       "\n",
       "                                                   poem form     topic  \n",
       "0     2 ABC of H.k. and China revised vision.\\nBarre...  abc       NaN  \n",
       "1     Apparently life without love, is no life at al...  abc       NaN  \n",
       "2     A abc angles on angels flaws (poem)\\nMix with ...  abc       NaN  \n",
       "3     A abc Brazil dance (poem)\\nJack of crack in po...  abc       NaN  \n",
       "4     ABC... I can't go on\\n123... what's the next o...  abc       NaN  \n",
       "...                                                 ...  ...       ...  \n",
       "8133  My friend, Sherla, was hard to see\\nfor Mom an...  NaN  children  \n",
       "8134  I have a shadow hooked to me.\\nSometimes he's ...  NaN  children  \n",
       "8135  The toothfairy took my tooth lath night\\nand l...  NaN  children  \n",
       "8136  Night-night moon\\nNight-night stars\\nNight-nig...  NaN  children  \n",
       "8137  A sapling in a severe drought\\nwhat she needs ...  NaN   romance  \n",
       "\n",
       "[8138 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"merged_dataset.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2d174db-b2b5-4817-8feb-d4b912fd04fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_labels(label_set):\n",
    "    label_encoder = preprocessing.LabelEncoder()\n",
    "    input_classes = label_set\n",
    "    label_encoder.fit(input_classes)\n",
    "    int_labels = label_encoder.transform(input_classes)\n",
    "    return int_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4cf9c757-28a9-4bba-aa06-5c8c605d519a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained('distilgpt2')\n",
    "special_tokens_dict = {\n",
    "    'bos_token': '<BOS>', \n",
    "    'eos_token': '<EOS>', \n",
    "    'pad_token': '<PAD>'}\n",
    "num_added_tokens = tokenizer.add_special_tokens(special_tokens_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "68bb7df5-04ae-4cc1-9302-42ef1f53d984",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPT2_Dataset(Dataset):\n",
    "    def __init__(self, file, tokenizer, max_length = max_len):\n",
    "        self.file = file\n",
    "        self.tokenizer = tokenizer\n",
    "        \n",
    "        self.data = pd.read_csv(file)\n",
    "        self.poems = [poem for poem in self.data['poem'].tolist() if len(poem) <= 300]\n",
    "        self.labels = self.data['topic'] if 'topic' in self.data else None\n",
    "\n",
    "        self.input_ids = []\n",
    "        self.attention_masks = []\n",
    "        for poem in self.poems:\n",
    "            encodings_dict = tokenizer('<BOS>' + poem + '<EOS>',\n",
    "                                         truncation=True,\n",
    "                                         max_length=max_length,\n",
    "                                         padding='max_length')\n",
    "            self.input_ids.append(torch.tensor(encodings_dict['input_ids']))\n",
    "            self.attention_masks.append(torch.tensor(encodings_dict['attention_mask']))\n",
    "\n",
    "        self.int_labels = encode_labels(self.labels)\n",
    "        \n",
    "    def __len__(self):\n",
    "         return len(self.input_ids)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.input_ids[idx], self.attention_masks[idx], self.int_labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3a0a3566-4e14-4bf7-b4cc-e1041d5bcc9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_dataset = GPT2_Dataset(\"topics_dataset.csv\", tokenizer=tokenizer)\n",
    "dataloader = DataLoader(topics_dataset, sampler=RandomSampler(topics_dataset), batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a801c44f-f37f-417d-82f7-ffe587733988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pad_index = 50259\n",
      "[tensor([[50257,  3629,   521,  ..., 50259, 50259, 50259],\n",
      "        [50257,    67,  2265,  ..., 50259, 50259, 50259],\n",
      "        [50257, 26807,   262,  ..., 50259, 50259, 50259],\n",
      "        [50257,    50,  9417,  ..., 50259, 50259, 50259],\n",
      "        [50257, 10725,  5357,  ..., 50259, 50259, 50259]]), tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]]), tensor([1, 2, 2, 2, 0])]\n"
     ]
    }
   ],
   "source": [
    "print('pad_index =', tokenizer.pad_token_id)\n",
    "for i, batch in enumerate(dataloader):\n",
    "    input_ids = batch[0]\n",
    "    attention_mask = batch[1]\n",
    "    labels = batch[2]\n",
    "    print(batch)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ae8aa39c-55aa-4cda-a7e4-34289a466ed3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "295"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#for poem in topics_dataset.poems:\n",
    "#   print(len(poem))\n",
    "len(topics_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e63690d1-e7e8-4ec0-a1b9-d67e2a4a27b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8ecb0510-aba6-4c4b-b786-a1813eee2415",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(50260, 768)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "configuration = GPT2Config(vocab_size=len(tokenizer)).from_pretrained('gpt2', output_hidden_states=True)\n",
    "poem_model = GPT2LMHeadModel.from_pretrained('gpt2', config=configuration)\n",
    "poem_model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d5bd5528-e6eb-4f24-9694-0f111c8b8d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(poem_model.parameters(), lr=learning_rate, eps=eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bb3130eb-29cf-47ce-bd9a-0b0ec9602407",
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "907cbdb1-c8d6-414b-a3fe-d747d76724f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "warmup_steps = 50\n",
    "total_steps = len(dataloader) * epochs\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
    "                                            num_warmup_steps=warmup_steps,\n",
    "                                            num_training_steps=total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0804453c-ff62-4f3a-a3ed-5ff80d013928",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['butterfly-tape-laser\", \"ItemImage467\" : \"/wcsstore//wcsstore/null/Set-F15662-10323']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#before training\n",
    "raw_model =  GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "prompt = \"butterfly\"\n",
    "input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids\n",
    "outputs = raw_model.generate(input_ids, do_sample=True, max_length=30)\n",
    "tokenizer.batch_decode(outputs, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fd2babcb-f0f2-42df-b9e7-30aba0934c86",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 of 40\n",
      "Epoch 2 of 40\n",
      "Epoch 3 of 40\n",
      "Epoch 4 of 40\n",
      "Epoch 5 of 40\n",
      "Epoch 6 of 40\n",
      "Epoch 7 of 40\n",
      "Epoch 8 of 40\n",
      "Epoch 9 of 40\n",
      "Epoch 10 of 40\n",
      "Epoch 11 of 40\n",
      "Epoch 12 of 40\n",
      "Epoch 13 of 40\n",
      "Epoch 14 of 40\n",
      "Epoch 15 of 40\n",
      "Epoch 16 of 40\n",
      "Epoch 17 of 40\n",
      "Epoch 18 of 40\n",
      "Epoch 19 of 40\n",
      "Epoch 20 of 40\n",
      "Epoch 21 of 40\n",
      "Epoch 22 of 40\n",
      "Epoch 23 of 40\n",
      "Epoch 24 of 40\n",
      "Epoch 25 of 40\n",
      "Epoch 26 of 40\n",
      "Epoch 27 of 40\n",
      "Epoch 28 of 40\n",
      "Epoch 29 of 40\n",
      "Epoch 30 of 40\n",
      "Epoch 31 of 40\n",
      "Epoch 32 of 40\n",
      "Epoch 33 of 40\n",
      "Epoch 34 of 40\n",
      "Epoch 35 of 40\n",
      "Epoch 36 of 40\n",
      "Epoch 37 of 40\n",
      "Epoch 38 of 40\n",
      "Epoch 39 of 40\n",
      "Epoch 40 of 40\n"
     ]
    }
   ],
   "source": [
    "model = poem_model.to(device)\n",
    "\n",
    "#model = nn.DataParallel(model)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f'Epoch {epoch + 1} of {epochs}')\n",
    "    total_loss = 0\n",
    "    model.train()\n",
    "    for i, batch in enumerate(dataloader): \n",
    "        input_ids = batch[0].to(device)\n",
    "        attention_mask = batch[1].to(device)\n",
    "        labels = batch[2].to(device)\n",
    "        \n",
    "        model.zero_grad()   \n",
    "        \n",
    "        outputs = model(input_ids, \n",
    "                        attention_mask=attention_mask,\n",
    "                        token_type_ids=None)\n",
    "        #print(outputs[0])\n",
    "        loss = outputs[0]\n",
    "        mean_loss = torch.mean(loss)\n",
    "        #print(f\"mean loss: {mean_loss}\")\n",
    "        batch_loss = loss.detach().cpu().numpy()\n",
    "        total_loss += batch_loss\n",
    "        \n",
    "        loss.sum().backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9719bfea-6c35-4318-9b39-d874ed465d15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/transformers/generation/utils.py:1270: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation )\n",
      "  warnings.warn(\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['butterfly']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#after fine-tuning\n",
    "model.eval()\n",
    "prompt = \"butterfly\"\n",
    "\n",
    "input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids\n",
    "outputs = model.generate(input_ids.to(device), do_sample=True, max_length=30)\n",
    "tokenizer.batch_decode(outputs, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2fc8dc5-f212-4cd4-9aaa-0eeb5e5f0629",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
